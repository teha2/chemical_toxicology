{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bayesian_NN_Train.ipynb","provenance":[{"file_id":"1BwkzZsfDyb0pSAeiN3Kg5hiwvTDrSDvw","timestamp":1607424277638}],"collapsed_sections":[],"mount_file_id":"1BwkzZsfDyb0pSAeiN3Kg5hiwvTDrSDvw","authorship_tag":"ABX9TyMPKxpah4uLPrVteGSoamuW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"yhrPQBJLPMH5"},"source":["# -*- Bayesian_NN_Train.py -*-\n","\"\"\"\n","Created Oct 2020\n","\n","@author: Timothy E H Allen / Alistair M Middleton\n","\"\"\"\n","#%%\n","\n","# Import modules\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow.compat.v2 as tf\n","import tensorflow_probability as tfp\n","import tqdm\n","import pandas as pd\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","import random\n","import seaborn as sns\n","from sklearn.metrics import mean_absolute_error\n","\n","tf.enable_v2_behavior()\n","tfd = tfp.distributions\n","\n","# Define inputs and variables\n","receptor = \"AR\"\n","input_data_a = \"/content/drive/My Drive/Training_Sets/\" + receptor + \" fingerprint.csv\"\n","input_data_b = \"/content/drive/My Drive/Test_Sets/\" + receptor + \" fingerprint.csv\"\n","rng_1 = 1989\n","rng_2 = 2020\n","validation_proportion = 0.25\n","neurons = 10\n","hidden_layers = 2\n","LR = 0.01\n","epochs = 100\n","batch_size= 100\n","model_path = \"/content/drive/My Drive/Models/\" + receptor + \"_quantitative_predictor\"\n","\n","def read_dataset(input_data):\n","    df = pd.read_csv(input_data)\n","    X = df[df.columns[0:10000]].values\n","    Y = df[df.columns[10000]]\n","    return X, Y\n","\n","# Load and shuffle data and make training and validation sets\n","\n","X, Y = read_dataset(input_data_a)\n","test_x, test_y = read_dataset(input_data_b)\n","X, Y = shuffle(X, Y, random_state=rng_1)\n","train_x, validation_x, train_y, validation_y = train_test_split(X, Y, test_size=validation_proportion, random_state=rng_2)\n","\n","# Note that the kl_loss_weight value here is 1 over the size of the entire dataset, not just the batch size.\n","\n","kl_loss_weight = 1 / train_x.shape[0]\n","\n","# Inspect the shape of the training and test data\n","\n","print(\"Dimensionality of data:\")\n","print(\"Train x shape =\", train_x.shape)\n","print(\"Train y shape =\", train_y.shape)\n","print(\"Validation x shape =\", validation_x.shape)\n","print(\"Validation y shape =\", validation_y.shape)\n","print(\"Test x shape =\", test_x.shape)\n","print(\"Test y shape =\", test_y.shape)\n","\n","\n","# Specify the surrogate posterior over `keras.layers.Dense` `kernel` and `bias`.\n","def posterior_mean_field(kernel_size, bias_size=0, dtype=None):\n","    n = kernel_size + bias_size\n","    c = np.log(np.expm1(1e-5))\n","    return tf.keras.Sequential([\n","        tfp.layers.VariableLayer(2 * n, dtype=dtype),\n","        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n","            tfd.Normal(loc=t[..., :n],\n","                       scale=1e-5 + tf.nn.softplus(c + t[..., n:])), \n","            reinterpreted_batch_ndims=1)),\n","    ])\n","\n","# Specify a non-trainable prior\n","def prior_not_trainable(kernel_size, bias_size=0, dtype=None):\n","    n = kernel_size + bias_size\n","    pi = .5\n","    return tf.keras.Sequential([\n","        tfp.layers.DistributionLambda(lambda t: tfd.Mixture(\n","            cat=tfd.Categorical(probs=[pi, 1. - pi]),\n","            components=[tfd.MultivariateNormalDiag(loc=tf.zeros(n), scale_diag=.001 * tf.ones(n)),\n","                        tfd.MultivariateNormalDiag(loc=tf.zeros(n), scale_diag=1.5 * tf.ones(n))\n","                        ])\n","                                      )\n","    ])\n","\n","\n","def negloglik(y, rv_y):\n","    return -rv_y.log_prob(y)\n","\n","# Specify model architecture\n","\n","if hidden_layers == 1:\n","    model_aleatoric_epistemic = tf.keras.Sequential([\n","        tfp.layers.DenseVariational(neurons, posterior_mean_field, prior_not_trainable, kl_weight=kl_loss_weight, activation='relu'),\n","        tfp.layers.DenseVariational(1 + 1, posterior_mean_field, prior_not_trainable, kl_weight=kl_loss_weight),\n","        tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t[..., :1], scale=1e-5 + tf.math.softplus(1e-5 * t[..., 1:]))) \n","        ])\n","    \n","elif hidden_layers == 2:\n","    model_aleatoric_epistemic = tf.keras.Sequential([\n","        tfp.layers.DenseVariational(neurons, posterior_mean_field, prior_not_trainable, kl_weight=kl_loss_weight, activation='relu'),\n","        tfp.layers.DenseVariational(neurons, posterior_mean_field, prior_not_trainable, kl_weight=kl_loss_weight, activation='relu'),\n","        tfp.layers.DenseVariational(1 + 1, posterior_mean_field, prior_not_trainable, kl_weight=kl_loss_weight),\n","        tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t[..., :1], scale=1e-5 + tf.math.softplus(1e-5 * t[..., 1:]))) \n","        ])\n","    \n","elif hidden_layers == 3:\n","    model_aleatoric_epistemic = tf.keras.Sequential([\n","        tfp.layers.DenseVariational(neurons, posterior_mean_field, prior_not_trainable, kl_weight=kl_loss_weight, activation='relu'),\n","        tfp.layers.DenseVariational(neurons, posterior_mean_field, prior_not_trainable, kl_weight=kl_loss_weight, activation='relu'),\n","        tfp.layers.DenseVariational(neurons, posterior_mean_field, prior_not_trainable, kl_weight=kl_loss_weight, activation='relu'),\n","        tfp.layers.DenseVariational(1 + 1, posterior_mean_field, prior_not_trainable, kl_weight=kl_loss_weight),\n","        tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t[..., :1], scale=1e-5 + tf.math.softplus(1e-5 * t[..., 1:]))) \n","        ])\n","    \n","else:\n","    print(\"Number of hidden layers outside this model scope, please choose 1, 2, or 3\")\n","\n","\n","# Train model\n","model = model_aleatoric_epistemic\n","model.compile(optimizer=tf.optimizers.Adam(learning_rate=LR), loss=negloglik, metrics=['mse'])\n","history = model.fit(train_x, train_y, epochs=epochs,verbose=True, validation_data=(validation_x, validation_y))\n","model.summary()\n","model.save(model_path, save_format = \"tf\")\n","\n","# Plot history of loss values\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()\n","\n","\n","# Plot history of MSE values\n","plt.plot(history.history['mse'])\n","plt.plot(history.history['val_mse'])\n","plt.title('model MSE')\n","plt.ylabel('MSE')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()\n","\n","# Calculate test data outputs\n","y_pred_list = []\n","for i in tqdm.tqdm(range(500)):\n","    y_pred = model.predict(test_x)\n","    y_pred_list.append(y_pred)\n","\n","y_preds = np.concatenate(y_pred_list, axis=1)\n","y_mean = np.mean(y_preds, axis=1)\n","y_sigma = np.std(y_preds, axis=1)\n","\n","# Plot experimental vs predicted values for test data\n","plt.figure()\n","plt.scatter(test_y,y_mean, marker='o')\n","\n","# Calculate and print mean absolute error values for the training and validation data alongside test result\n","y_pred_list = []\n","for i in tqdm.tqdm(range(500)):\n","    y_pred = model.predict(train_x)\n","    y_pred_list.append(y_pred)\n","\n","y_preds = np.concatenate(y_pred_list, axis=1)\n","y_mean_train = np.mean(y_preds, axis=1)\n","y_sigma_train = np.std(y_preds, axis=1)\n","\n","y_pred_list = []\n","for i in tqdm.tqdm(range(500)):\n","    y_pred = model.predict(validation_x)\n","    y_pred_list.append(y_pred)\n","\n","y_preds = np.concatenate(y_pred_list, axis=1)\n","y_mean_validation = np.mean(y_preds, axis=1)\n","y_sigma_validation = np.std(y_preds, axis=1)\n","\n","print(\"Training Set MAE:\")\n","print(mean_absolute_error(train_y, y_mean_train))\n","print(\"Validation Set MAE:\")\n","print(mean_absolute_error(validation_y, y_mean_validation))\n","print(\"Test Set MAE:\")\n","print(mean_absolute_error(test_y, y_mean))\n","\n","\n","# End the cycle\n","tf.keras.backend.clear_session()\n","\n","# Endgame\n","print(\"END\")"],"execution_count":null,"outputs":[]}]}